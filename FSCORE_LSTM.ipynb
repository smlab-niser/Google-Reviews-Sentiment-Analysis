{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FSCORE LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e3txwbh3q76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "097e3f2c-6084-4ddb-baad-b918f445f7c3"
      },
      "source": [
        "\n",
        "!pip install numpy==1.16.2\n",
        "\n",
        "\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "\n",
        "vocab_size = 10000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.googleplay.load_data(num_words=vocab_size)\n",
        "\n",
        "\n",
        "class_names = [\"Negative\", \"Positive\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.6/dist-packages (1.16.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E05AweFu0Imt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "word_index = tf.keras.datasets.googleplay.get_word_index()\n",
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNKNOWN>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFXK-g6G81sC",
        "colab_type": "text"
      },
      "source": [
        "## **FSCORE OF LSTM + GLOVE**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD1qHVBn81Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatonate UTKAL REVIEWS test and training datasets\n",
        "allreviews = np.concatenate((x_train, x_test), axis=0)\n",
        "\n",
        "print(\"Maximum review length: {}\".format(len(max((allreviews), key=len))))\n",
        "print(\"Minimum review length: {}\".format(len(min((allreviews), key=len))))\n",
        "result = [len(x) for x in allreviews]\n",
        "print(\"Mean review length: {}\".format(np.mean(result)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"googleplay Review\")\n",
        "print(\"  Review Text: \" + str(x_train[60]))\n",
        "print(\"  Review Sentiment: \" + str(y_train[60]))\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"UTKAL TEST Review\")\n",
        "print(\"  Review Text: \" + decode_review(x_train[60]))\n",
        "print(\"  Review Sentiment: \" + class_names[y_train[60]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF-Votm66zD5",
        "colab_type": "text"
      },
      "source": [
        "## **Pre-processing Data (PADDING GOOGLE PLAY STORE DATASET)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNtJTLJA6gaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "review_length = 500\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = review_length)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Shape Training Review Data: \" + str(x_train.shape))\n",
        "print(\"Shape Training Class Data: \" + str(y_train.shape))\n",
        "print(\"Shape Test Review Data: \" + str(x_test.shape))\n",
        "print(\"Shape Test Class Data: \" + str(y_test.shape))\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Google Review Text (post padding): \" + decode_review(x_train[60]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfOdV_VCCFee",
        "colab_type": "text"
      },
      "source": [
        "## **Create and build LSTM + GLOVE ON GOOGLEPLAY DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nmO8M4aCKwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "58b748ab-6b90-41e2-c5b0-0a7a5b9c91ca"
      },
      "source": [
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, # The size of our vocabulary \n",
        "        output_dim = 32, # each words shall be mapped\n",
        "        input_length = review_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.CuDNNLSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add a second dropout layer to Google dataset with the same aim as the first.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 \n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) \n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           320000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)       (None, 32)                8448      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,481\n",
            "Trainable params: 328,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xx1Q2I8WNI9",
        "colab_type": "text"
      },
      "source": [
        "## **Visualise the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KdfAoHsGwzo",
        "colab_type": "text"
      },
      "source": [
        "## **Train the LSTM + GLOVE ON GOOGLE REVIEW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEN1vV4nG1V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the LSTM + GLOVE  on the google reviews training data\n",
        "history = model.fit(\n",
        "\n",
        "    \n",
        "    x_train, y_train,\n",
        "                    \n",
        " \n",
        "    batch_size=256, \n",
        "\n",
        "    epochs=3, \n",
        "    \n",
        "\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpCS2-jFH1KY",
        "colab_type": "text"
      },
      "source": [
        "## **Evaluate model with UTKAL REVIEW test data and view results FSCORE ON PLAYSTORE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPnfxwbnITqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "08493db5-a14a-40aa-cdf4-33b46b6b68d1"
      },
      "source": [
        "# Get Model Predictions for utkal reviews test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(x_test)\n",
        "print(classification_report(y_test, predicted_classes, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.86      0.90      0.88     12500\n",
            "    Positive       0.90      0.86      0.88     12500\n",
            "\n",
            "    accuracy                           0.88     25000\n",
            "   macro avg       0.88      0.88      0.88     25000\n",
            "weighted avg       0.88      0.88      0.88     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}