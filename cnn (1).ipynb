{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zQoILT9e-z2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c187804-30b0-47ae-8db4-e1be1ea5cfa0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pxf4Qu3xe-0E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "0816947d-a042-4c71-da71-54990b77a989"
      },
      "source": [
        "playstore = keras.datasets.playstore\n",
        "\n",
        "# as features\n",
        "num_words = 20000\n",
        "\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = dataset.load_data(num_words=num_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c1962c65fc20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplaystore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaystore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# as features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.datasets' has no attribute 'playstore'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BGBirQQ2l1h7"
      },
      "source": [
        "The argument num_words=20000 keeps the top 20,000 most frequently occurring words in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GDRePL1flhhw",
        "colab": {}
      },
      "source": [
        "print(\"Training examples: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdVN8hYGloP7"
      },
      "source": [
        "The text of reviews have been converted to integers, where each integer represents a specific word in a dictionary. Here's what the first review looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gO0nNEZklltp",
        "colab": {}
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x6Bbi27-ltzb",
        "colab": {}
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A2JwvoSve-0H",
        "colab": {}
      },
      "source": [
        "\n",
        "max_len = 500\n",
        "\n",
        "# Convert our lists of integers into 2D tensors\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, \n",
        "                                                        maxlen=max_len)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, \n",
        "                                                       maxlen=max_len)\n",
        "\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MvAGi0aPmsRH",
        "colab": {}
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rl_sY4nFe-0N",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "\n",
        "embedding_dimension = 16\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, embedding_dimension, input_length=max_len))\n",
        "\n",
        "\n",
        "# 'GlobalAveragePooling` \n",
        "model.add(GlobalAveragePooling1D())\n",
        "\n",
        "# classifier \n",
        "model.add(Dense(1, activation='sigmoid') )\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "96uw4Szxe-0b",
        "colab": {}
      },
      "source": [
        "# word to integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index[i] for i in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FZaYLC13flhp",
        "colab": {}
      },
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N7o16O-aUlzv",
        "colab": {}
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # 1000, 16. Each word is mapped to an embedding vector."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2q09l-8WB0j",
        "colab": {}
      },
      "source": [
        "out_v = open('vecs.tsv', 'w')\n",
        "out_m = open('meta.tsv', 'w')\n",
        "for word_num in range(num_words):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0yuZjaYRWG2A",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('vecs.tsv')\n",
        "files.download('meta.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yN7uoh4h1eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download pretrained GloVe embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhU6eKZQh1eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH4l9UrKh1eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnvhM_Hlh1ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_dir = './'\n",
        "\n",
        "embeddings_index = {} #initialize dictionary\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQAmLW3h1eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim)) #create an array of zeros with word_num rows and embedding_dim columns\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < num_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpmC85wWh1ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import initializers, models, regularizers\n",
        "from keras.layers import Dense, Dropout, Embedding, SeparableConv1D, MaxPooling1D, GlobalAveragePooling1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRxAGnXQh1em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sequential model\n",
        "cnnModel = models.Sequential()\n",
        "\n",
        "#embedding layer\n",
        "cnnModel.add(Embedding(num_words, \n",
        "                    embedding_dim, \n",
        "                    input_length=max_len,\n",
        "                      weights=[embedding_matrix],\n",
        "                      trainable=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYz3c6fTh1et",
        "colab_type": "text"
      },
      "source": [
        "Our sepCNN is defined as blocks. Each block will be made up as follows:\n",
        "* Dropout Layer\n",
        "* SepConv1D Layer\n",
        "* SepConv1D Layer\n",
        "* MaxPooling Layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQUzjLxGh1eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blocks = 4\n",
        "dropout_rate = 0.3\n",
        "filters = 50 \n",
        "kernel_size = 5 \n",
        "for _ in range(blocks):\n",
        "    cnnModel.add(Dropout(rate=dropout_rate))\n",
        "    cnnModel.add(SeparableConv1D(filters=filters,\n",
        "                             kernel_size= kernel_size,\n",
        "                             activation= 'relu',\n",
        "                             bias_initializer= 'random_uniform',\n",
        "                             depthwise_initializer= 'random_uniform',\n",
        "                             padding= 'same'))\n",
        "    cnnModel.add(SeparableConv1D(filters=filters,\n",
        "                             kernel_size= kernel_size,\n",
        "                             activation= 'relu',\n",
        "                             bias_initializer= 'random_uniform',\n",
        "                             depthwise_initializer= 'random_uniform',\n",
        "                             padding= 'same'))\n",
        "    cnnModel.add(MaxPooling1D(pool_size=pool_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX1mWbPgh1ey",
        "colab_type": "text"
      },
      "source": [
        " adding layers:\n",
        "* SeparableConv1D\n",
        "* SeparableConv1D\n",
        "* GlobalAveragePooling1D\n",
        "* Dropout\n",
        "* Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKzwUs4ih1ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnModel.add(SeparableConv1D(filters=filters * 2,\n",
        "                         kernel_size= kernel_size,\n",
        "                         activation= 'relu',\n",
        "                         bias_initializer= 'random_normal',\n",
        "                         depthwise_initializer= 'random_normal',\n",
        "                         padding='same'))\n",
        "cnnModel.add(SeparableConv1D(filters=filters * 2,\n",
        "                         kernel_size= kernel_size,\n",
        "                         activation= 'relu',\n",
        "                         bias_initializer= 'random_normal',\n",
        "                         depthwise_initializer= 'random_normal',\n",
        "                         padding='same'))\n",
        "cnnModel.add(GlobalAveragePooling1D())\n",
        "cnnModel.add(Dropout(rate= dropout_rate))\n",
        "cnnModel.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "723-syMLh1e1",
        "colab_type": "text"
      },
      "source": [
        "At this point, we have the beginnings of a deep convolutional neural network. We can see the architecture in it's entirity below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpRrztOTh1e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G3Jkbnmh1e6",
        "colab_type": "text"
      },
      "source": [
        "train the model and test and validate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpgE8WJJh1e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imODuveth1e-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnModel.compile(optimizer=Adam(0.1), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP0JPoxOh1fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = cnnModel.fit(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    batch_size=512,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OpX_glNh1fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}