{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zQoILT9e-z2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb52a330-ffe1-4754-f198-3ff3547091ea"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pxf4Qu3xe-0E",
        "colab": {}
      },
      "source": [
        "db = keras.datasets.googleplay\n",
        "\n",
        "\n",
        "num_words = 20000\n",
        "\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = googleplay.load_data(num_words=num_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GDRePL1flhhw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64ba8f56-847f-47fc-ee17-0825e51ae24a"
      },
      "source": [
        "print(\"Training examples: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gO0nNEZklltp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7f9b25f2-6ba1-409d-8727-3a27423d8fe8"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x6Bbi27-ltzb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bed21543-b621-465b-9a2a-9854db01d021"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A2JwvoSve-0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "393a478f-1624-4dc2-a844-bfa09ffacb40"
      },
      "source": [
        "\n",
        "max_len = 500\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, \n",
        "                                                        maxlen=max_len)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, \n",
        "                                                       maxlen=max_len)\n",
        "\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MvAGi0aPmsRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6a05df18-f10e-48e9-ce9a-01d1e3732fe1"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     1    14    22    16    43   530\n",
            "   973  1622  1385    65   458  4468    66  3941     4   173    36   256\n",
            "     5    25   100    43   838   112    50   670     2     9    35   480\n",
            "   284     5   150     4   172   112   167     2   336   385    39     4\n",
            "   172  4536  1111    17   546    38    13   447     4   192    50    16\n",
            "     6   147  2025    19    14    22     4  1920  4613   469     4    22\n",
            "    71    87    12    16    43   530    38    76    15    13  1247     4\n",
            "    22    17   515    17    12    16   626    18 19193     5    62   386\n",
            "    12     8   316     8   106     5     4  2223  5244    16   480    66\n",
            "  3785    33     4   130    12    16    38   619     5    25   124    51\n",
            "    36   135    48    25  1415    33     6    22    12   215    28    77\n",
            "    52     5    14   407    16    82 10311     8     4   107   117  5952\n",
            "    15   256     4     2     7  3766     5   723    36    71    43   530\n",
            "   476    26   400   317    46     7     4 12118  1029    13   104    88\n",
            "     4   381    15   297    98    32  2071    56    26   141     6   194\n",
            "  7486    18     4   226    22    21   134   476    26   480     5   144\n",
            "    30  5535    18    51    36    28   224    92    25   104     4   226\n",
            "    65    16    38  1334    88    12    16   283     5    16  4472   113\n",
            "   103    32    15    16  5345    19   178    32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rl_sY4nFe-0N",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "b6d174e9-0b82-4d4a-c377-87df511cd7a4"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "\n",
        "embedding_dimension = 16\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, embedding_dimension, input_length=max_len))\n",
        "\n",
        "\n",
        "model.add(GlobalAveragePooling1D())\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='ReLu') )\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 16)           320000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 320,017\n",
            "Trainable params: 320,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 6s 298us/step - loss: 0.6723 - acc: 0.6895 - val_loss: 0.6342 - val_acc: 0.7728\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 6s 290us/step - loss: 0.5795 - acc: 0.8067 - val_loss: 0.5277 - val_acc: 0.8170\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 6s 281us/step - loss: 0.4762 - acc: 0.8497 - val_loss: 0.4457 - val_acc: 0.8516\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 6s 286us/step - loss: 0.3999 - acc: 0.8728 - val_loss: 0.3944 - val_acc: 0.8644\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 6s 297us/step - loss: 0.3462 - acc: 0.8896 - val_loss: 0.3577 - val_acc: 0.8738\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 6s 323us/step - loss: 0.3078 - acc: 0.8993 - val_loss: 0.3335 - val_acc: 0.8778\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 8s 390us/step - loss: 0.2784 - acc: 0.9079 - val_loss: 0.3156 - val_acc: 0.8830\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 8s 401us/step - loss: 0.2550 - acc: 0.9148 - val_loss: 0.3034 - val_acc: 0.8868\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 6s 319us/step - loss: 0.2349 - acc: 0.9215 - val_loss: 0.2939 - val_acc: 0.8890\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 6s 281us/step - loss: 0.2182 - acc: 0.9276 - val_loss: 0.2869 - val_acc: 0.8916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "96uw4Szxe-0b",
        "colab": {}
      },
      "source": [
        "\n",
        "word_index = dataset.get_word_index()\n",
        "\n",
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index[i] for i in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N7o16O-aUlzv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1654fa8f-dc2a-42a1-a2c6-c5a9fb1bfe5d"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2q09l-8WB0j",
        "colab": {}
      },
      "source": [
        "out_v = open('vecs.tsv', 'w')\n",
        "out_m = open('meta.tsv', 'w')\n",
        "for word_num in range(num_words):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0yuZjaYRWG2A",
        "colab": {},
        "outputId": "239854d7-4944-4bd7-a40f-c367576ecc67"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('vecs.tsv')\n",
        "files.download('meta.tsv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4ab75b70af1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vecs.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meta.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MdqOmgeYpCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download pretrained GloVe embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckZkbVEHYpCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgJrxjR0YpCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52sZzYlKYpCZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "cfd17d54-ee1e-4fcd-8464-e60f5190d05f"
      },
      "source": [
        "glove_dir = './'\n",
        "\n",
        "embeddings_index = {} \n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i-Qk3yLYpCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim)) #create an array of zeros with word_num rows and embedding_dim columns\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < num_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmpeU7dXYpCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import initializers, models, regularizers\n",
        "from keras.layers import Dense, Dropout, Embedding, SeparableConv1D, MaxPooling1D, GlobalAveragePooling1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOLkIHCCYpCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cnnModel = models.Sequential()\n",
        "\n",
        "\n",
        "cnnModel.add(Embedding(num_words, \n",
        "                    embedding_dim, \n",
        "                    input_length=max_len,\n",
        "                      weights=[embedding_matrix],\n",
        "                      trainable=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCCPi9zxYpCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blocks = 4 # int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "dropout_rate = 0.3 # float, percentage of input to drop at Dropout layers. Recommended range 0.2-0.5\n",
        "filters = 50 # int, output dimension of the layers. Recommended range 50 - 300\n",
        "kernel_size = 5 #int, length of the convolution window. Recommended values 3 or 5\n",
        "pool_size = 1 # int, factor by which to downscale input at MaxPooling layer.\n",
        "\n",
        "for _ in range(blocks):\n",
        "    cnnModel.add(Dropout(rate=dropout_rate))\n",
        "    cnnModel.add(SeparableConv1D(filters=filters,\n",
        "                             kernel_size= kernel_size,\n",
        "                             activation= 'relu',\n",
        "                             bias_initializer= 'random_uniform',\n",
        "                             depthwise_initializer= 'random_uniform',\n",
        "                             padding= 'same'))\n",
        "    cnnModel.add(SeparableConv1D(filters=filters,\n",
        "                             kernel_size= kernel_size,\n",
        "                             activation= 'relu',\n",
        "                             bias_initializer= 'random_uniform',\n",
        "                             depthwise_initializer= 'random_uniform',\n",
        "                             padding= 'same'))\n",
        "    cnnModel.add(MaxPooling1D(pool_size=pool_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s-J3WjPYpC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnModel.add(SeparableConv1D(filters=filters * 2,\n",
        "                         kernel_size= kernel_size,\n",
        "                         activation= 'relu',\n",
        "                         bias_initializer= 'random_normal',\n",
        "                         depthwise_initializer= 'random_normal',\n",
        "                         padding='same'))\n",
        "cnnModel.add(SeparableConv1D(filters=filters * 2,\n",
        "                         kernel_size= kernel_size,\n",
        "                         activation= 'relu',\n",
        "                         bias_initializer= 'random_normal',\n",
        "                         depthwise_initializer= 'random_normal',\n",
        "                         padding='same'))\n",
        "cnnModel.add(GlobalAveragePooling1D())\n",
        "cnnModel.add(Dropout(rate= dropout_rate))\n",
        "cnnModel.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53HWWyVgYpC-",
        "colab_type": "code",
        "colab": {},
        "outputId": "f3addf15-2d8a-4c84-fc51-06a921a5c8df"
      },
      "source": [
        "cnnModel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 500, 100)          2000000   \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 500, 100)          0         \n",
            "_________________________________________________________________\n",
            "separable_conv1d_47 (Separab (None, 500, 50)           5550      \n",
            "_________________________________________________________________\n",
            "separable_conv1d_48 (Separab (None, 500, 50)           2800      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "separable_conv1d_49 (Separab (None, 500, 50)           2800      \n",
            "_________________________________________________________________\n",
            "separable_conv1d_50 (Separab (None, 500, 50)           2800      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "separable_conv1d_51 (Separab (None, 500, 50)           2800      \n",
            "_________________________________________________________________\n",
            "separable_conv1d_52 (Separab (None, 500, 50)           2800      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "separable_conv1d_53 (Separab (None, 500, 50)           2800      \n",
            "_________________________________________________________________\n",
            "separable_conv1d_54 (Separab (None, 500, 50)           2800      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "separable_conv1d_55 (Separab (None, 500, 100)          5350      \n",
            "_________________________________________________________________\n",
            "separable_conv1d_56 (Separab (None, 500, 100)          10600     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,041,201\n",
            "Trainable params: 41,201\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFy3emZAYpDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4-8-fPsYpDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnModel.compile(optimizer=Adam(0.1), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPozaVTUYpDO",
        "colab_type": "code",
        "colab": {},
        "outputId": "92328eb4-47a5-451f-83b4-a90b1fdb0e9f"
      },
      "source": [
        "history = cnnModel.fit(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    batch_size=512,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/3\n",
            "20000/20000 [==============================] - 246s 12ms/step - loss: 0.6955 - acc: 0.4998 - val_loss: 0.6946 - val_acc: 0.4938\n",
            "Epoch 2/3\n",
            "20000/20000 [==============================] - 235s 12ms/step - loss: 0.6940 - acc: 0.5009 - val_loss: 0.6946 - val_acc: 0.4938\n",
            "Epoch 3/3\n",
            "20000/20000 [==============================] - 228s 11ms/step - loss: 0.6936 - acc: 0.4993 - val_loss: 0.6933 - val_acc: 0.4938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtK9iGs3YpDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}